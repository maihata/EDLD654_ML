---
title: "autism_project"
author: "Maiko Hata"
format: html
editor: visual
---

```{r}
library(dplyr)
library(finalfit)
library(lubridate)
library(reticulate)
library(finalfit)
library(stringr)
library(recipes)
library(ggplot2)
```

```{r}
setwd("~/Desktop/EDLD654_ML")
```

### Following the steps on Kaggle **Assignment 1**

Task 1.1. Read data

```{r}
autism <- read.csv('/Users/maiko/Desktop/EDLD654_ML/data/Autism_Screening.csv', header=TRUE)
```

```{r}
str(autism)
```

Task 1.2. through Task 1.8. Recode cyclical data, text data ‚Äì N/A\
Task 1.3. Recode text data into binary variable\
‚Äî\> start here by recoding gender, jundice, autism, class/ASD as binary?

```{r}
autism$gender_binary <- ifelse(autism$gender == "m", 1, 0)
autism$jundice_binary <- ifelse(autism$jundice == "yes", 1, 0)
autism$Class.ASD_binary <- ifelse(autism$Class.ASD == "YES", 1, 0)

# It made a new column, will need to delete original later 
```

```{r}
head(autism[c("gender", "gender_binary")])
```

```{r}
table(autism$gender_binary)
```

Task 2.2 Using the `ff_glimpse()` function from the `finalfit` package, provide a snapshot of missingness in this dataset. This function also returns the number of levels for categorical variables. If there is any variable with large amount of missingness (e.g. more than 75%), remove this variable from the dataset.

```{r}
ff_glimpse(autism)
```

```{r}
ff_glimpse(autism[, 1:20])
```

```{r}
autism <- autism[, colMeans(is.na(autism)) <= 0.75]
```

```{r}
str(autism)
```

‚úÖ 1Ô∏è‚É£ Count how many ‚Äú?‚Äù entries exist in `ethnicity`

```{r}
sum(autism$ethnicity == "?", na.rm = TRUE)
```

‚úÖ 2Ô∏è‚É£ Check total rows (for percentage)

```{r}
nrow(autism)
```

‚úÖ 3Ô∏è‚É£ Compute percentage of missing (‚Äú?‚Äù) entries (--\> I decided it's good enough, as the example from class had 75% threshold)

```{r}
mean(autism$ethnicity == "?", na.rm = TRUE) * 100
```

Yep‚Äîthose quotes are literally part of the values (e.g., `'United States'` vs `Bahamas`). That comes from inconsistent quoting in the source or how it was imported, and it will bite you later because they‚Äôll become different factor levels.

```{r}
# library(readr)
# autism <- read_csv("data/Autism_Data.csv", quote = "\"'")
```

If you‚Äôve already loaded it, clean the column

```{r}
library(dplyr)
library(stringr)

autism <- autism %>%
  mutate(
    contry_of_res = str_trim(contry_of_res),
    # remove leading/trailing single or double quotes
    contry_of_res = str_replace_all(contry_of_res, "^[\"']+|[\"']+$", ""),
    # collapse internal extra spaces
    contry_of_res = str_squish(contry_of_res),
    # optional: normalize common variants
    contry_of_res = recode(contry_of_res,
      "USA" = "United States", "U.S." = "United States",
      "United States of America" = "United States"
    )
  )

```

```{r}
autism %>% count(contry_of_res, sort = TRUE)
```

Fixing the "ethnicity" column the same way as above to remove ' " etc.

```{r}
autism <- autism %>%
  mutate(
    ethnicity = str_trim(ethnicity),
    ethnicity = str_replace_all(ethnicity, "^[\"']+|[\"']+$", ""),
    ethnicity = str_squish(ethnicity)
    )

```

‚úÖ If you‚Äôre done using the original columns\
If you‚Äôve already converted variables like `gender`, `jaundice`, `family_mem_with_asd`, etc. into `_binary` versions (0/1) and those originals were categorical or text,\
then yes ‚Äî you can safely remove them to avoid redundancy before modeling.

```{r}
# autism <- autism %>%
#  select(-gender, -jaundice, -family_mem_with_asd)

```

‚ö†Ô∏è If you‚Äôre still exploring or not sure yet\
Keep both for now! You can always drop the original columns later once you‚Äôve confirmed that: 1) the `_binary` variables are correctly coded (0 for No, 1 for Yes, etc.) 2) and your model runs fine without the originals.

```{r}

```

ASD Diagnosis Data Analysis and Prediction (<https://www.kaggle.com/code/devraai/asd-diagnosis-data-analysis-and-prediction-model>)\
‚Äî Data Cleaning ‚Äî

üß© In your **autism dataset** ‚Äì If `age` is already text (e.g., `"18"`, `"2.5"`, `"?"`, `"n/a"`), then you don‚Äôt need `format()` ‚Äî just convert directly:

```{r}
autism$age <- as.numeric(autism$age)
```

```{r}
sum(is.na(autism$age))
```

```{r}
# Checking to make sure "result" column is numeric already 
is.numeric(autism$result)
```

From <https://www.kaggle.com/code/devraai/asd-diagnosis-data-analysis-and-prediction-model>:

```{r}
# Distribution of ASD Class

ggplot(autism, aes(x = Class.ASD, fill = Class.ASD)) +
  geom_bar() +
  scale_fill_manual(values = c("NO" = "#69b3a2", "YES" = "#404080")) +
  labs(title = "Distribution of Autism Class",
       x = "Autism Class", y = "Count") +
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.title = element_text(hjust = 0.5)
  )
```

```{r}
ggplot(autism, aes(x = age)) +
  geom_histogram(binwidth = 0.5) +
  labs(title = "Age Distribution",
       x = "Age",
       y = "Count") +
  theme_minimal()
```

```{r}

ggplot(autism, aes(x = age)) +
  geom_histogram(binwidth = 0.5) +
  scale_x_continuous(limits = c(0, max(autism$age, na.rm = TRUE) + 10)) +
  labs(title = "Age Distribution",
       x = "Age",
       y = "Count") +
  theme_minimal()

```

```{r}
# Trying to remove that weird error/outliner age around 380 years old 
summary(autism$age)
```

```{r}
autism <- autism %>% 
  filter(age <= 100)
```

```{r}
# Trying again to see if the 383 got removed -- and it's much better! üôå
ggplot(autism, aes(x = age)) +
  geom_histogram(binwidth = 0.5) +
  labs(title = "Age Distribution",
       x = "Age",
       y = "Count") +
  theme_minimal()

```

```{r}
autism <- autism %>% 
  filter(age <= 100)

ggplot(autism, aes(x = age)) +
  geom_histogram(binwidth = 0.5, fill = "steelblue") +
  labs(title = "Age Distribution",
       x = "Age",
       y = "Count") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

```

```{r}
# Because the column "result" was numeric, I should be able to plot it hte same way: 
ggplot(autism, aes(x = result)) +
  geom_histogram(binwidth = 0.5) +
  labs(title = "Result Distribution",
       x = "Result",
       y = "Count") +
  theme_minimal()

```

```{r}
ggplot(autism, aes(x = result)) +
  geom_histogram(binwidth = 0.5, fill = "steelblue") +
  labs(title = "Screener Results",
       x = "Score",
       y = "Count") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

**Assignment 1: Task 2.3** Most of the variables in this dataset are categorical, and particularly a binary variable with a Yes and No response. Check the frequency of unique values for all categorical variables. If there is any inconsistency (e.g., Yes is coded as both 'y' and 'Y') for any of these variables in terms of how values are coded, fix them. Also, check the distribution of numeric variables and make sure there is no anomaly.

```{r}
names(autism)
```

```{r}
# Categorical variables
cat_vars <- c(
  "gender", 
  "ethnicity", 
  "jundice",       # use your dataset‚Äôs spelling
  "austim",        # same spelling as in your data
  "contry_of_res", # same spelling as in your data
  "Class.ASD"
)

# Numeric variables
num_vars <- c(
  "age"
)
### result is OUTCOME, so we exclude it ###

# Binary-coded versions 
binary_vars <- c(
  "gender_binary",
  "jundice_binary",
  "Class.ASD_binary"
)
```

```{r}
list(
  categorical = cat_vars,
  numerical = num_vars,
  binary = binary_vars
)
```

```{r}
invisible(lapply(cat_vars, function(v) {
  cat("\n---", v, "---\n")
  print(table(autism[[v]], useNA = "ifany"))
}))

```

```{r}
summary(autism[num_vars])
```

```{r}
ggplot(autism, aes(x = ethnicity)) +
  geom_bar(fill = "steelblue") +
  labs(title = "Race/Ethnicity",
       x = "Race/Ethnicity",
       y = "Count") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
ggplot(autism, aes(x = ethnicity)) +
  geom_bar(fill = "steelblue") +
  geom_text(aes(label = after_stat(count)),
            stat = "count",
            vjust = -0.5, size = 3.5) +
  labs(title = "Race/Ethnicity",
       x = "Race/Ethnicity",
       y = "Count") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.x = element_text(angle = 45, hjust = 1))
```

**Assignment 1: Task 2.3** Most of the variables in this dataset are categorical, and particularly a binary variable with a Yes and No response. Check the frequency of unique values for all categorical variables. If there is any inconsistency (e.g., Yes is coded as both 'y' and 'Y') for any of these variables in terms of how values are coded, fix them. Also, check the distribution of numeric variables and make sure there is no anomaly.

---\> There is no inconsistencies (I already checked and changed it (like countries to have no " ").

---\> I already checked for numerical anomaly by running summary(autism\$age) and filtered it out with autism \<- autism %\>% filter(age \<= 100)

### ‚úÖ Step 3 ‚Äî Build the modeling dataframe

why: we drop the original text columns you already replaced (gender/jundice/Class.ASD) and keep only what we‚Äôll transform.

```{r}
autism_mod <- autism |>
  transmute(
    # outcome
    result,
    # numeric predictors
    age,
    # keep these categoricals to one-hot later
    ethnicity, contry_of_res, austim,
    # keep your existing 0/1 binaries as numeric predictors
    gender_binary, jundice_binary, Class.ASD_binary
  )
```

### ‚úÖ 4) choose numeric vars for polynomial expansion

why: you only have age as a numeric predictor; we‚Äôll create degree-3 raw polynomial terms for it.

```{r}
num_poly_ok <- "age"
```

### ‚úÖ 5) define the recipe (steps only; no training yet)

### chunk 1 ‚Äî recipe skeleton (declare outcome and predictors implicitly)

why: tells recipes that result is the numeric outcome; everything else in autism is a predictor.

```{r}
rec <- recipe(result ~ ., data = autism)
```

### chunk 2 ‚Äî steps (1)‚Äì(4): na indicators, zero-variance, impute numeric, impute categorical

```{r}
rec <- rec |>
  step_indicate_na(all_predictors()) |>        # (1)
  step_zv(all_predictors()) |>                 # (2) catch single-level nominals like age_desc
  step_impute_mean(all_numeric_predictors()) |># (3)
  step_impute_mode(all_nominal_predictors())   # (4)
```

### chunk 3 ‚Äî steps (5)‚Äì(7): polynomial(age, deg=3), standardize, one-hot dummies

```{r}
rec <- rec |>
  step_poly(age, degree = 3, options = list(raw = TRUE)) |>  # (5)
  step_normalize(all_numeric_predictors()) |>                # (6)
  step_dummy(all_nominal_predictors(), one_hot = TRUE)       # (7)
```

### chunk 4 ‚Äî prep (train the recipe)

why: learns means, modes, and scaling parameters from your data.

```{r}
### Redid the chunks 2 and 3 because "You hit a known quirk of this dataset: it has a column age_desc that‚Äôs always '18 and more' (only one level). step_dummy() chokes on single-level factors. Update chunks 2‚Äì3 to remove zero-variance columns for all predictors (not just numeric):" which makes sense. 
rec_prep <- prep(rec, training = autism, verbose = TRUE)
```

### chunk 5 ‚Äî blueprint

```{r}
rec_prep
tidy(rec_prep)
```

### Bake it! 

```{r}
autism_xf <- bake(rec_prep, new_data = NULL)
```

```{r}
head(autism)
```

```{r}
autism_final <- autism_xf |>
  dplyr::rename(score = result) |>
  dplyr::relocate(score)
```

```{r}
View(autism_final)
```

```{r}
### 701 rows, 112 variables(features) ### 
dim(autism_final)
names(autism_final)[1:20]
```

```{r}

```

```{r}

```
