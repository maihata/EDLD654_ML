---
title: "EDLD654 Final Project"
author: "Maiko Hata"
format:
  revealjs:
    theme: serif
    footer: "EDLD654 Final Project - Maiko Hata"
editor: visual
---

```{r}
# "Beautiful presentations with R and Quarto" https://youtu.be/01KifhHDkFk?si=2axQMI_c0Tu9_Z5P 
# quarto themes  https://quarto.org/docs/presentations/revealjs/themes.html
# theme - serif or simple
```

```{r}
library(dplyr)
library(finalfit)
library(lubridate)
library(reticulate)
library(finalfit)
library(stringr)
library(recipes)
library(ggplot2)
library(tidyverse)
library(gt)
```

## Research Problem

The big question: How can I design and apply ML models without reinforcing existing biases?

![](images/Asian_student_turned_white.png){fig-align="center"}

## Research Question

-   **Goal**: Predict Autism Spectrum Quotient (AQ-10) screener scores from demographic information.

-   **Potential benefit**: Understanding factors relating to scores can potentially support more focused outreach.

-   **Ethical & equity considerations**: As an Autistic researcher and Early Intervention (EI) specialist, I want to understand how predictive models are created, their limitations, and ethical considerations.

```{r}
# Machine learning is a topic that holds many layers and emotions. There are clear benefits, such as identifying patterns in large datasets that improve efficiency and flow across fields. However, the use of big data without consent from the individuals it represents raises serious ethical concerns, including the misuse of sensitive information and the reinforcement of existing biases. For example, an Asian MIT student recently received a “White” version of her image when she requested a professional headshot generated by AI (Bhaimiya, 2023). As she later reflected, “this has catalyzed a larger conversation around AI bias and who is or isn’t included in this new wave of technology” (Wang, as cited in Growcoot, 2023).
```

## Data

-   From Kaggle

    -   **Numerical** (age, screener result)
    -   **Binary** (gender f/m, jaundice yes/no, family history of Autism yes/no, used app before yes/no, results from screener results YES (7+) NO (\~6)
    -   **Text** (ethnicity, country of residence)

::: center
![](images/Autism_Spectrum_dataset.png){fig-align="center" width="60%"}
:::

```{r}
#I looked for dataset on Kaggle as recommended by Lina. There were a few Autism related datasets, and I chose this one based on the columns and the score for “ease of use”. I really had ethical dilemma, though, reducing complex lives of people down to just these columns. As an Autism consultant who spends 20+ hours to evaluate infants and toddlers for educational Autism eligibility, I really didn’t want to use the binary outcome of YES Autism or NO Autism based on an online screener of 10 questions, especially because it seemed like if you had a score of 7+, you were “yes Autism” group. So, I decided to use the total score of 0-10 as the numerical, continuous outcomes that i will try to predict. 
```

## Data 

When you click the **Render** button a presentation will be generated that includes both content and the output of embedded code. You can embed code like this:

## Code

Cleaning up

```{r}
#| echo: true 
#| fig-align: center
# #| output-location: makes the plot go next page, or column etc. 




```

## Code

When you click the **Render** button a presentation will be generated that includes both content and the output of embedded code. You can embed code like this:

## Code

When you click the **Render** button a presentation will be generated that includes both content and the output of embedded code. You can embed code like this:

```{r}
1 + 1
```

```{r}

```

```{r}

```

```{r}

```

```{r}

```
